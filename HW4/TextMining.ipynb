{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "  for l in urllib.request.urlopen(fname):\n",
    "    yield eval(l)\n",
    "    \n",
    "print (\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:5000]\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique unigram count: 36225\n",
      "Unique bigram count: 237209\n",
      "Unique unigram count without punc/capitalization: 19426\n",
      "Unique bigram count without punc/capitalization: 182902\n",
      "Unique bigram count without punc/capitalization: 182902\n"
     ]
    }
   ],
   "source": [
    "#Number of unique words\n",
    "from collections import Counter\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "  for w in d['review/text'].split():\n",
    "    wordCount[w] += 1\n",
    "    \n",
    "print(\"Unique unigram count: \" +str(len(wordCount)))\n",
    "\n",
    "wordCount = defaultdict(lambda : defaultdict(int))\n",
    "uniqueBigramCount = 0\n",
    "prev = ''\n",
    "for d in data:\n",
    "    for w in d['review/text'].split():\n",
    "        if prev not in wordCount:\n",
    "            uniqueBigramCount += 1\n",
    "        elif prev in wordCount and w not in wordCount[prev]:\n",
    "            uniqueBigramCount += 1\n",
    "        wordCount[prev][w] += 1\n",
    "        prev = w\n",
    "    prev = ''\n",
    "    \n",
    "print(\"Unique bigram count: \" +str(uniqueBigramCount))\n",
    "\n",
    "uwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if c not in punctuation])\n",
    "    for w in r.split():\n",
    "        uwordCount[w]+=1\n",
    "\n",
    "print(\"Unique unigram count without punc/capitalization: \"+str(len(uwordCount)))\n",
    "\n",
    "wordCount = defaultdict(lambda : defaultdict(int))\n",
    "bwordCount = defaultdict(lambda: 0)\n",
    "uniqueBigramCount = 0\n",
    "prev = ''\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if c not in punctuation])\n",
    "    for w in r.split():\n",
    "        if prev not in wordCount:\n",
    "            uniqueBigramCount += 1\n",
    "        elif prev in wordCount and w not in wordCount[prev]:\n",
    "            uniqueBigramCount += 1\n",
    "        wordCount[prev][w] += 1\n",
    "        bwordCount[prev+','+w] += 1\n",
    "        prev = w\n",
    "    prev = ''\n",
    "    \n",
    "print(\"Unique bigram count without punc/capitalization: \" +str(uniqueBigramCount))\n",
    "print(\"Unique bigram count without punc/capitalization: \" +str(len(bwordCount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['with,a', 4587]\n",
      "['in,the', 2595]\n",
      "['of,the', 2245]\n",
      "['is,a', 2056]\n",
      "['on,the', 2033]\n"
     ]
    }
   ],
   "source": [
    "counts = [(bwordCount[w], w) for w in bwordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [[x[1], x[0]] for x in counts[:1000]]\n",
    "\n",
    "#most frequent bigrams\n",
    "for i in range(5):\n",
    "    print(words[i])\n",
    "    \n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    prev = ''\n",
    "    for w in r.split():\n",
    "        bigram = prev + ',' + w\n",
    "        if bigram in words:\n",
    "            feat[wordId[bigram]] += 1\n",
    "        prev = w\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343976376659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y, predictions)) #0.343976376659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 30695\n",
      "the 27569\n",
      "and 19512\n",
      "of 15935\n",
      "is 12623\n"
     ]
    }
   ],
   "source": [
    "ucounts = [(uwordCount[w], w) for w in uwordCount]\n",
    "ucounts.sort()\n",
    "ucounts.reverse()\n",
    "\n",
    "words = [x[1] for x in ucounts[:1000]]\n",
    "\n",
    "#most frequent unigrams\n",
    "for i in range(5):\n",
    "    print(words[i], ucounts[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "the\n",
      "and\n",
      "of\n",
      "is\n",
      "with\n",
      "to\n",
      "this\n",
      "i\n",
      "it\n",
      "in\n",
      "but\n",
      "beer\n",
      "that\n",
      "very\n",
      "head\n",
      "with,a\n",
      "not\n",
      "as\n",
      "for\n",
      "on\n",
      "some\n",
      "was\n",
      "taste\n",
      "nice\n",
      "good\n",
      "hops\n",
      "light\n",
      "malt\n",
      "like\n",
      "one\n",
      "from\n",
      "in,the\n",
      "its\n",
      "at\n",
      "carbonation\n",
      "dark\n",
      "bit\n",
      "more\n",
      "sweet\n",
      "flavor\n",
      "of,the\n",
      "an\n",
      "little\n",
      "my\n",
      "aroma\n",
      "is,a\n",
      "on,the\n",
      "well\n",
      "hop\n",
      "there\n",
      "a,bit\n",
      "chocolate\n",
      "glass\n",
      "be\n",
      "color\n",
      "finish\n",
      "lacing\n",
      "just\n",
      "pours\n",
      "this,is\n",
      "smell\n",
      "mouthfeel\n",
      "up\n",
      "no\n",
      "into\n",
      "this,beer\n",
      "really\n",
      "and,a\n",
      "much\n",
      "out\n",
      "body\n",
      "have\n",
      "all\n",
      "a,little\n",
      "you\n",
      "are\n",
      "bitter\n",
      "caramel\n",
      "than\n",
      "has\n",
      "had\n",
      "bitterness\n",
      "bottle\n",
      "alcohol\n",
      "poured\n",
      "medium\n",
      "notes\n",
      "a,nice\n",
      "nose\n",
      "would\n",
      "me\n",
      "citrus\n",
      "too\n",
      "can\n",
      "s\n",
      "malts\n",
      "t\n",
      "smooth\n",
      "great\n"
     ]
    }
   ],
   "source": [
    "combinedCount = ucounts + counts\n",
    "combinedCount.sort()\n",
    "combinedCount.reverse()\n",
    "\n",
    "words = [x[1] for x in combinedCount[:1000]]\n",
    "\n",
    "#most frequent combined unigrams + bigrams\n",
    "for i in range(100):\n",
    "    print(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature1(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    prev = ''\n",
    "    for w in r.split():\n",
    "        bigram = prev + ',' + w\n",
    "        if bigram in words:\n",
    "            feat[wordId[bigram]] += 1\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "        prev = w\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.424951133062\n"
     ]
    }
   ],
   "source": [
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "#combined unigram+bigram model\n",
    "print(mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at,a', 'tastes,like', 'a,pale', 'no,lacing', 'the,bitterness']\n"
     ]
    }
   ],
   "source": [
    "leastWeightGrams = [words[i] for i in theta.argsort()[:5]]\n",
    "print(leastWeightGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['up,a', 'the,best', 'easy,to', 'i,love', 'very,drinkable']\n"
     ]
    }
   ],
   "source": [
    "mostWeightGrams = [words[i] for i in theta.argsort()[-6:] if i != len(words)]\n",
    "print(mostWeightGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
