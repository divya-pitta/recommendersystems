{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseData(fname):\n",
    "  for l in urllib.request.urlopen(fname):\n",
    "    yield eval(l)\n",
    "    \n",
    "print (\"Reading data...\")\n",
    "data = list(parseData(\"http://jmcauley.ucsd.edu/cse190/data/beer/beer_50000.json\"))[:5000]\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique unigram count: 36225\n",
      "Unique bigram count: 237209\n",
      "Unique unigram count without punc/capitalization: 19426\n",
      "Unique bigram count without punc/capitalization: 182902\n",
      "Unique bigram count without punc/capitalization: 182902\n"
     ]
    }
   ],
   "source": [
    "#Number of unique words\n",
    "from collections import Counter\n",
    "\n",
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "  for w in d['review/text'].split():\n",
    "    wordCount[w] += 1\n",
    "    \n",
    "print(\"Unique unigram count: \" +str(len(wordCount)))\n",
    "\n",
    "wordCount = defaultdict(lambda : defaultdict(int))\n",
    "uniqueBigramCount = 0\n",
    "prev = ''\n",
    "for d in data:\n",
    "    for w in d['review/text'].split():\n",
    "        if prev not in wordCount:\n",
    "            uniqueBigramCount += 1\n",
    "        elif prev in wordCount and w not in wordCount[prev]:\n",
    "            uniqueBigramCount += 1\n",
    "        wordCount[prev][w] += 1\n",
    "        prev = w\n",
    "    prev = ''\n",
    "    \n",
    "print(\"Unique bigram count: \" +str(uniqueBigramCount))\n",
    "\n",
    "uwordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if c not in punctuation])\n",
    "    for w in r.split():\n",
    "        uwordCount[w]+=1\n",
    "\n",
    "print(\"Unique unigram count without punc/capitalization: \"+str(len(uwordCount)))\n",
    "\n",
    "wordCount = defaultdict(lambda : defaultdict(int))\n",
    "bwordCount = defaultdict(lambda: 0)\n",
    "uniqueBigramCount = 0\n",
    "prev = ''\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if c not in punctuation])\n",
    "    for w in r.split():\n",
    "        if prev not in wordCount:\n",
    "            uniqueBigramCount += 1\n",
    "        elif prev in wordCount and w not in wordCount[prev]:\n",
    "            uniqueBigramCount += 1\n",
    "        wordCount[prev][w] += 1\n",
    "        bwordCount[prev+','+w] += 1\n",
    "        prev = w\n",
    "    prev = ''\n",
    "    \n",
    "print(\"Unique bigram count without punc/capitalization: \" +str(uniqueBigramCount))\n",
    "print(\"Unique bigram count without punc/capitalization: \" +str(len(bwordCount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['with,a', 4587]\n",
      "['in,the', 2595]\n",
      "['of,the', 2245]\n",
      "['is,a', 2056]\n",
      "['on,the', 2033]\n"
     ]
    }
   ],
   "source": [
    "counts = [(bwordCount[w], w) for w in bwordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "words = [[x[1], x[0]] for x in counts[:1000]]\n",
    "\n",
    "#most frequent bigrams\n",
    "for i in range(5):\n",
    "    print(words[i])\n",
    "    \n",
    "words = [x[1] for x in counts[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    prev = ''\n",
    "    for w in r.split():\n",
    "        bigram = prev + ',' + w\n",
    "        if bigram in words:\n",
    "            feat[wordId[bigram]] += 1\n",
    "        prev = w\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [feature(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343976376659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y, predictions)) #0.343976376659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 30695\n",
      "the 27569\n",
      "and 19512\n",
      "of 15935\n",
      "is 12623\n"
     ]
    }
   ],
   "source": [
    "ucounts = [(uwordCount[w], w) for w in uwordCount]\n",
    "ucounts.sort()\n",
    "ucounts.reverse()\n",
    "\n",
    "words = [x[1] for x in ucounts[:1000]]\n",
    "\n",
    "#most frequent unigrams\n",
    "for i in range(5):\n",
    "    print(words[i], ucounts[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "the\n",
      "and\n",
      "of\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "combinedCount = ucounts + counts\n",
    "combinedCount.sort()\n",
    "combinedCount.reverse()\n",
    "\n",
    "words = [x[1] for x in combinedCount[:1000]]\n",
    "\n",
    "#most frequent combined unigrams + bigrams\n",
    "for i in range(5):\n",
    "    print(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "\n",
    "def feature1(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    prev = ''\n",
    "    for w in r.split():\n",
    "        bigram = prev + ',' + w\n",
    "        if bigram in words:\n",
    "            feat[wordId[bigram]] += 1\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "        prev = w\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.288822120305\n"
     ]
    }
   ],
   "source": [
    "X = [feature1(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "#combined unigram+bigram model\n",
    "print(mean_squared_error(y, predictions)) #0.288822120305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sort,of', 'water', 'corn', 'the,background', 'straw']\n"
     ]
    }
   ],
   "source": [
    "leastWeightGrams = [words[i] for i in theta.argsort()[:5]]\n",
    "print(leastWeightGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not,bad', 'the,best', 'of,these', 'a,bad', 'sort']\n"
     ]
    }
   ],
   "source": [
    "mostWeightGrams = [words[i] for i in theta.argsort()[-6:] if i != len(words)]\n",
    "print(mostWeightGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = defaultdict(lambda: defaultdict(int))\n",
    "idf = defaultdict(int)\n",
    "\n",
    "for d in data:\n",
    "    r = ''.join([c for c in d['review/text'].lower() if c not in punctuation])\n",
    "    wordsInDoc = defaultdict(int)\n",
    "    for w in r.split():\n",
    "        wordsInDoc[w] += 1\n",
    "    for u in wordsInDoc:\n",
    "        idf[u] += 1\n",
    "\n",
    "totalDocCount = len(data)\n",
    "import math\n",
    "for t in idf:\n",
    "    idf[t] = math.log(totalDocCount/idf[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foam idf: 2.6200393237794968\n",
      "Banana idf: 3.8632328412587142\n",
      "Smell idf: 1.238564249095555\n",
      "Lactic idf: 6.725433722188183\n",
      "Tart idf: 4.160484364726646\n",
      "A idf: 0.014098924379501675\n"
     ]
    }
   ],
   "source": [
    "print(\"Foam idf: \"+ str(idf['foam']))\n",
    "print(\"Banana idf: \"+ str(idf['banana']))\n",
    "print(\"Smell idf: \"+str(idf['smell']))\n",
    "print(\"Lactic idf: \"+str(idf['lactic']))\n",
    "print(\"Tart idf: \"+str(idf['tart']))\n",
    "print(\"A idf: \"+str(idf['a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a lot of foam but a lot\tin the smell some banana and then lactic and tart not a good start\tquite dark orange in color with a lively carbonation now visible under the foam\tagain tending to lactic sourness\tsame for the taste with some yeast and banana\n",
      "Foam tf-idf: 5.2400786475589936\n",
      "Banana tf-idf: 7.7264656825174285\n",
      "Smell tf-idf: 1.238564249095555\n",
      "Lactic tf-idf: 13.450867444376366\n",
      "Tart tf-idf: 4.160484364726646\n",
      "A tf-idf: 0.0563956975180067\n"
     ]
    }
   ],
   "source": [
    "review1 = ''.join([c for c in data[0]['review/text'].lower() if c not in punctuation])\n",
    "print(review1)\n",
    "tf = defaultdict(int)\n",
    "for w in review1.split():\n",
    "    tf[w] += 1\n",
    "print(\"Foam tf-idf: \"+ str(idf['foam']*tf['foam']))\n",
    "print(\"Banana tf-idf: \"+ str(idf['banana']*tf['banana']))\n",
    "print(\"Smell tf-idf: \"+str(idf['smell']*tf['smell']))\n",
    "print(\"Lactic tf-idf: \"+str(idf['lactic']*tf['lactic']))\n",
    "print(\"Tart tf-idf: \"+str(idf['tart']*tf['tart']))\n",
    "print(\"A tf-idf: \"+str(idf['a']*tf['a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "the\n",
      "and\n",
      "of\n",
      "is\n"
     ]
    }
   ],
   "source": [
    "words = [x[1] for x in ucounts[:1000]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "\n",
    "#sanity check\n",
    "for a in range(5):\n",
    "    print(words[a])\n",
    "    \n",
    "def feature2(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['review/text'].lower() if not c in punctuation])\n",
    "    tf = defaultdict(int)\n",
    "    for w in r.split():\n",
    "        if w in words:\n",
    "            tf[w] += 1\n",
    "    for w in tf:\n",
    "        feat[wordId[w]] = tf[w]*idf[w]\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.278742490057\n"
     ]
    }
   ],
   "source": [
    "X = [feature2(d) for d in data]\n",
    "y = [d['review/overall'] for d in data]\n",
    "\n",
    "#With regularization\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "theta = clf.coef_\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "#Tf-IDF model\n",
    "print(mean_squared_error(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
